{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc6e8098",
   "metadata": {},
   "source": [
    "\n",
    "# Importing Related Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "716c2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import psutil\n",
    "import time\n",
    "process = psutil.Process()\n",
    "!\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pandas import set_option\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics, tree\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, auc, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e95dc3b",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d623fb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/vaibh/Desktop/NEHA_PROJECT/diabetes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m diabetes_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/vaibh/Desktop/NEHA_PROJECT/diabetes.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Import diabetes dataset\u001b[39;00m\n\u001b[1;32m      3\u001b[0m diabetes_data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/python/3.12.1/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/vaibh/Desktop/NEHA_PROJECT/diabetes.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "diabetes_data = pd.read_csv('C:/Users/vaibh/Desktop/NEHA_PROJECT/diabetes.csv') # Import diabetes dataset\n",
    "diabetes_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010601f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cdd42d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Information of datasets\n",
    "print(\"The scale of data is\", diabetes_data.shape, \"\\n\")\n",
    "diabetes_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca05e04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Statistical of datasets\n",
    "# Drop the PatientID columns and transpose the data\n",
    "diabetes_data.drop(columns=['PatientID']).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a1eb47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reviewing Skew of Attribute Distribution\n",
    "skew_value = diabetes_data.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c3500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness_values = pd.DataFrame({\n",
    "    'Variable': diabetes_data.columns,\n",
    "    'Skewness': skew_value\n",
    "})\n",
    "plt.figure(figsize=(20,8))\n",
    "# Plot the skewness values using a barplot\n",
    "sns.barplot(x='Variable', y='Skewness', data=skewness_values)\n",
    "\n",
    "# Add labels and a title to the plot\n",
    "\n",
    "plt.xlabel(\"Features\",size=15)\n",
    "plt.ylabel(\"Skewness\",size=15)\n",
    "plt.title(\"Skewness of Variables in Diabetes Dataset\",size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd92c06",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e01e87b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Histrogram for each attribute in dataset\n",
    "diabetes_data.hist(figsize=(15,15),column=diabetes_data.drop(columns=['PatientID']).columns,color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4601db4c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Class distribution to preview diabetic statistics\n",
    "result = diabetes_data.groupby('Diabetic').size()\n",
    "print(result)\n",
    "ax = result.plot(kind='bar',color='purple',label='0 - No Diabetic')\n",
    "ax = result.plot(kind='bar',color='purple',label='1 - Diabetic')\n",
    "ax.legend(loc='best')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97955576",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the feature matrix and target vector before feature selection\n",
    "X = diabetes_data.drop(columns=['Diabetic'])\n",
    "y = diabetes_data['Diabetic']\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172cf81a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Box and Whisker Plots\n",
    "X.plot(figsize=(20,20),kind='box',subplots=True,layout=(3,3),sharex=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37761e66",
   "metadata": {},
   "source": [
    "# Feature Selection Method \n",
    "\n",
    "### Filter Method\n",
    "Filter methods are a type of feature selection method that works by selecting features based on some criteria prior to building the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e32ad5",
   "metadata": {},
   "source": [
    "In our example dataset, all of the features are numeric.\n",
    "Hence, we cannot remove any feature from feature matrix through filter method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0d456",
   "metadata": {},
   "source": [
    "### Pearson’s correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e950d6",
   "metadata": {},
   "source": [
    "Correlation between each features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4142e51e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reviewing Correlation between attributes\n",
    "correlations = round(X.corr(),4)\n",
    "correlations # 1 represent full positive correlation, -1 represent negative correllation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5711acec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize the resulting correlation matrix using a heatmap:\n",
    "\n",
    "plt.figure(figsize=(15,12))\n",
    "sns.heatmap(correlations, annot=True,cmap ='RdBu_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aab7ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop over bottom diagonal of correlation matrix\n",
    "for i in range(len(correlations.columns)):\n",
    "    for j in range(i):\n",
    "        # Print variables with high correlation\n",
    "        if abs(correlations.iloc[i, j]) > 0.7:\n",
    "            print(correlations.columns[i], correlations.columns[j], correlations.iloc[i, j])\n",
    "else:\n",
    "    print('The coefficient of each features not greater than 0.7')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce93e29",
   "metadata": {},
   "source": [
    "Normally, we define high correlation as having a coefficient of greater than 0.7 or less than -0.7. We use loop to check each feature correlation matrix and realize unneccessary to drop any feature since the each features correlation not greater than 0.7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c723754",
   "metadata": {},
   "source": [
    "Correlation between features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f6ce7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Merge features and targets together for checking correlation\n",
    "X_y = X.copy()\n",
    "X_y['Diabetic'] = y\n",
    "print(X_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f08df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation = X_y.corr()\n",
    "correlation_target = correlation[['Diabetic']].drop(labels=['Diabetic'])\n",
    "correlation_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a614e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(correlation_target, annot=True, fmt='.3', cmap='RdBu_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e25be8",
   "metadata": {},
   "source": [
    "From the heatmap above, we can observe the correlation coefficient of PatientID is smaller. We can consider to remove it from datasets if we want to save the times and costs in model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['PatientID'])\n",
    "print(X.columns) # Check the feature matrix\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b1a80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaler = pd.DataFrame(scaler.fit_transform(X),columns=['Pregnancies', 'PlasmaGlucose', 'DiastolicBloodPressure',\n",
    "       'TricepsThickness', 'SerumInsulin', 'BMI', 'DiabetesPedigree', 'Age'])\n",
    "X_scaler.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7020c27c",
   "metadata": {},
   "source": [
    "# Importing model training and feature selection libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be9eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "# from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509ca392",
   "metadata": {},
   "source": [
    "### Wrapper Method Function (Sequential Forward Selection with Supervised Learning Algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e2453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def feature_selection(dt_model, x_data):\n",
    "    \n",
    "    # Ensure the random distributions are same when execute \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    sfs = SFS(dt_model,\n",
    "          k_features=8,\n",
    "          forward=True,\n",
    "          floating=False,\n",
    "          scoring='accuracy',\n",
    "          cv=5)\n",
    "    \n",
    "    sfs.fit(x_data, y)\n",
    "    \n",
    "    print('Feature selection: \\n\\n')\n",
    "    for idx, score in sfs.subsets_.items():\n",
    "    \tprint(idx,':', score, '\\n')\n",
    "    \n",
    "    print('Model Accuracy: \\n\\n')\n",
    "    for idx, score in sfs.subsets_.items():\n",
    "        print(idx,':', score['avg_score'].round(4)*100, '%')\n",
    "    \n",
    "    plot_sfs(sfs.get_metric_dict())\n",
    "    plt.grid()\n",
    "    plt.title('Accuracy vs Number of Features')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c48f6f",
   "metadata": {},
   "source": [
    "### Define the confusion matrix plotting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8d744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix_plot(conf_matrix):\n",
    "    \n",
    "    ax = sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues')\n",
    "\n",
    "    ax.set_title('Confusion Matrix with labels\\n\\n');\n",
    "    ax.set_xlabel('\\nPredicted Values')\n",
    "    ax.set_ylabel('Actual Values ');\n",
    "\n",
    "    ## Ticket labels - List must be in alphabetical order\n",
    "    ax.xaxis.set_ticklabels(['Negative','Positive'])\n",
    "    ax.yaxis.set_ticklabels(['Negative','Positive'])\n",
    "\n",
    "    ## Display the visualization of the Confusion Matrix.\n",
    "    plt.plot(conf_matrix)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fec965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_report_plot(class_report):\n",
    "    \n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.title('Model Classification Report\\n\\n')\n",
    "    sns.heatmap(class_report, annot=True,  fmt='g')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e209f4",
   "metadata": {},
   "source": [
    "### Define the AUC ROC plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc(model,y_test,y_predicted):\n",
    "    \n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_predicted)\n",
    "    auc = round(metrics.roc_auc_score(y_test, y_predicted), 4)\n",
    "    plt.plot(fpr,tpr,color='red', linestyle='--', marker='o', linewidth=2, label= model+\" AUC=\"+str(auc))\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.title('AUC ROC of '+ model)\n",
    "    plt.xlabel('False Positive')\n",
    "    plt.ylabel('True Positive')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21bf8d4",
   "metadata": {},
   "source": [
    "### Decision Tree Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef52b74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Decision Tree Algorithm\n",
    "start_time = time.time()\n",
    "initial_memory = process.memory_info().rss\n",
    "\n",
    "dt_model = DecisionTreeClassifier()\n",
    "    \n",
    "# Import feature_selection function\n",
    "feature_selection(dt_model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b6cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    " # From wrapper method, we know which features removed was useful to increase accuracy of model.\n",
    "X_data = X[['Pregnancies', 'PlasmaGlucose', 'TricepsThickness', 'SerumInsulin', 'BMI', 'Age']]\n",
    "\n",
    "# Split 80% data for training set\n",
    "X_rem, X_test, y_rem, y_test = train_test_split(X_data, y, test_size=0.25, random_state=6)\n",
    "\n",
    "# Split 10% data for validation set and 10% for test set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_rem, y_rem, train_size=0.9, random_state=6)\n",
    "\n",
    "dt_model.fit(X_train,y_train)\n",
    "\n",
    "# Using validation set to observe the accuracy during model training\n",
    "y_val_pred = dt_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation set accuracy after feature selection: \", round(accuracy*100,2), \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eba7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "\n",
    "# parameters = {\n",
    "#     'max_depth': [2,4,6,8,10],\n",
    "#     'max_leaf_nodes': [10,15,20,25,30,35,40]\n",
    "# }\n",
    "\n",
    "# dt_model = DecisionTreeClassifier()\n",
    "# random = RandomizedSearchCV(dt_model, parameters, n_iter=30)\n",
    "# random.fit(X_train,y_train)\n",
    "\n",
    "# df = pd.concat([pd.DataFrame(random.cv_results_['params']), pd.DataFrame(random.cv_results_['mean_test_score']*100, columns=['Accuracy'])] ,axis=1)\n",
    "# display(df.sort_values('Accuracy', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b706cfb8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(max_depth=10, max_leaf_nodes=40)\n",
    "\n",
    "dt_model.fit(X_train,y_train)\n",
    "\n",
    "# Using validation set to get the accuracy after model training\n",
    "y_val_pred = dt_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation set accuracy after hyperparameter tuning: \", round(accuracy*100,2), \"%\\n\")\n",
    "\n",
    "y_predicted_dt = dt_model.predict(X_test)\n",
    "y_prob_dt = dt_model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predicted_dt)\n",
    "print(\"Decision Tree Model Test Set Accuracy: \", round(accuracy*100,2), \"%\\n\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_predicted_dt)\n",
    "print(\"Decision Tree Model Confusion Matrix: \\n\")\n",
    "conf_matrix_plot(conf_matrix)\n",
    "\n",
    "class_report = pd.DataFrame(classification_report(y_test, y_predicted_dt, output_dict=True)).transpose()\n",
    "print(\"Decision Tree Model Classification Report: \\n\")\n",
    "class_report_plot(class_report)\n",
    "    \n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "\n",
    "final_memory = process.memory_info().rss\n",
    "memory_usage = final_memory - initial_memory\n",
    "\n",
    "print(\"Memory usage:\", memory_usage, 'bytes\\n')\n",
    "print(\"Runtime:\", round(run_time,2), 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d782fe61",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18cc14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_selection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m initial_memory \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mmemory_info()\u001b[38;5;241m.\u001b[39mrss\n\u001b[1;32m      4\u001b[0m knn_model \u001b[38;5;241m=\u001b[39m KNeighborsClassifier()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mfeature_selection\u001b[49m(knn_model, X_scaler)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_selection' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "initial_memory = process.memory_info().rss\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "feature_selection(knn_model, X_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719dd5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X_scaler[['Pregnancies', 'SerumInsulin', 'BMI', 'Age']]\n",
    "\n",
    "# Split 80% data for training set\n",
    "X_rem, X_test, y_rem, y_test = train_test_split(X_data, y, test_size=0.25, random_state=6)\n",
    "\n",
    "# Split 10% data for validation set and 10% for test set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_rem, y_rem, train_size=0.9, random_state=6)\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train,y_train)\n",
    "\n",
    "# Using validation set to observe the accuracy during model training\n",
    "y_val_pred = knn_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation set accuracy after feature selection: \", round(accuracy*100,2), \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09da530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the best value of K in KNN\n",
    "score_list = []\n",
    "for k in range(1,50):\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train,y_train)\n",
    "    score = model.score(X_val, y_val)\n",
    "    score_list.append(score*100)\n",
    "\n",
    "max_score = max(score_list)\n",
    "\n",
    "k = [idx+1 for idx, score in enumerate(score_list) if score == max_score]\n",
    "print(f'The maximum accuracy is {max_score} when the K value is {k} after feature selection.\\n')\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(range(1,50), score_list, color='blue', linestyle='dashed', marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.title('Accurracy vs K value',size=20)\n",
    "plt.xlabel('K',size=18)\n",
    "plt.ylabel('Accuracy Percentage',size=18)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a5fadc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(6)\n",
    "\n",
    "knn_model.fit(X_train,y_train)\n",
    "\n",
    "# Using validation set to get the accuracy after model training\n",
    "y_val_pred = knn_model.predict(X_val)\n",
    "y_prob_knn = knn_model.predict_proba(X_test)[:, 1]  \n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation set accuracy after hyperparameter tuning: \", round(accuracy*100,2), \"%\\n\")\n",
    "\n",
    "y_predicted_knn = knn_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_predicted_knn)\n",
    "print(\"K Nearest Neighbor Model Test Set Accuracy: \", round(accuracy*100,2), \"%\\n\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_predicted_knn)\n",
    "print(\"K Nearest Neighbor Model Confusion Matrix: \\n\")\n",
    "conf_matrix_plot(conf_matrix)\n",
    "\n",
    "class_report = pd.DataFrame(classification_report(y_test, y_predicted_knn, output_dict=True)).transpose()\n",
    "print(\"K Nearest Neighbor Model Classification Report: \\n\")\n",
    "class_report_plot(class_report)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "\n",
    "final_memory = process.memory_info().rss\n",
    "memory_usage = final_memory - initial_memory\n",
    "\n",
    "print(\"Memory usage:\", memory_usage, 'bytes\\n')\n",
    "\n",
    "print(\"Runtime:\", round(run_time,2), 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973eb9ed",
   "metadata": {},
   "source": [
    "### Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7272be6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Logistic Regression Algorithm\n",
    "start_time = time.time()\n",
    "initial_memory = process.memory_info().rss\n",
    "\n",
    "# The initial value of maximum iteration cannot converge\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Import feature_selection function\n",
    "feature_selection(lr_model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd49145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 80% data for training set\n",
    "X_rem, X_test, y_rem, y_test = train_test_split(X, y, test_size=0.25, random_state=6)\n",
    "\n",
    "# Split 10% data for validation set and 10% for test set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_rem, y_rem, train_size=0.9, random_state=6)\n",
    "\n",
    "lr_model.fit(X_train,y_train)\n",
    "\n",
    "# Using validation set to observe the accuracy during model training\n",
    "y_val_pred = lr_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation set accuracy after feature selection: \", round(accuracy*100,2), \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd544c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = []\n",
    "test_array = []\n",
    "C_array = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for x in C_array:\n",
    "    clf_new = LogisticRegression(max_iter=1000, C=x)\n",
    "    clf_new.fit(X_train,y_train)\n",
    "    y_pred_train = clf_new.predict(X_train)\n",
    "    train_array.append(accuracy_score(y_pred_train,y_train))\n",
    "    y_pred_val = clf_new.predict(X_val)\n",
    "    test_array.append(accuracy_score(y_pred_val,y_val))\n",
    "\n",
    "plt.plot(C_array,train_array, color='blue', linestyle='dashed', marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.plot(C_array,test_array, color='orange', linestyle='dashed', marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.legend(['Training set', 'Validation set'])\n",
    "plt.title('Choose the range of best C value')\n",
    "plt.xlabel('Range of C in log format')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid()\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd157c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# C_range = np.logspace(-2,2,100)\n",
    "\n",
    "# parameters = {'C': C_range, 'penalty':['l1','l2'], 'solver':['saga','lbfgs']}\n",
    "\n",
    "# lr_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# grid = GridSearchCV(lr_model, parameters, cv=3)\n",
    "\n",
    "# grid.fit(X_train,y_train)\n",
    "\n",
    "# print(\"Best parameters:\", grid.best_params_, \"\\n\")\n",
    "# print(\"Best score:\", round(grid.best_score_*100,2), \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abaaa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Algorithm\n",
    "lr_model = LogisticRegression(max_iter=10000,C=0.059,penalty='l2',solver='lbfgs')\n",
    "\n",
    "lr_model.fit(X_train,y_train)\n",
    "\n",
    "# Using validation set to get the accuracy after model training\n",
    "y_val_pred = lr_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation set accuracy after hyperparameter tuning: \", round(accuracy*100,2), \"%\\n\")\n",
    "\n",
    "# Using test set to get the accuracy after model training\n",
    "\n",
    "y_predicted_lr = lr_model.predict(X_test)\n",
    "y_prob_lr = lr_model.predict_proba(X_test)[:, 1]  \n",
    "accuracy = accuracy_score(y_test,y_predicted_lr)\n",
    "print(\"Logistic Regression Model Test set accuracy: \", round(accuracy*100,2), \"%\\n\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_predicted_lr)\n",
    "print(\"Logistic Regression Model Confusion Matrix: \\n\")\n",
    "conf_matrix_plot(conf_matrix)\n",
    "\n",
    "class_report = pd.DataFrame(classification_report(y_test,y_predicted_lr, output_dict=True)).transpose()\n",
    "print(\"Logistic Regression Model Classification Report: \\n\")\n",
    "class_report_plot(class_report)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "\n",
    "final_memory = process.memory_info().rss\n",
    "memory_usage = final_memory - initial_memory\n",
    "\n",
    "print(\"Memory usage:\", memory_usage, 'bytes\\n')\n",
    "\n",
    "print(\"Runtime:\", round(run_time,2), 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f8c9d4",
   "metadata": {},
   "source": [
    "### Random Forests Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e4f8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "initial_memory = process.memory_info().rss\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "feature_selection(rf_model,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ad433",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X[['Pregnancies', 'PlasmaGlucose', 'DiastolicBloodPressure', 'TricepsThickness', 'SerumInsulin', 'BMI', 'Age']]\n",
    "   \n",
    "# Split 80% data for training set\n",
    "X_rem, X_test, y_rem, y_test = train_test_split(X_data, y, test_size=0.25, random_state=10)\n",
    "\n",
    "# Split 10% data for validation set and 10% for test set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_rem, y_rem, train_size=0.9, random_state=10)\n",
    "\n",
    "rf_model.fit(X_train,y_train)\n",
    "\n",
    "# Using validation set to observe the accuracy during model training\n",
    "y_val_pred = rf_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation set accuracy after feature selection: \", round(accuracy*100,2), \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f5a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "np.random.seed(0)\n",
    "depths = range(1,40)\n",
    "for i in depths:\n",
    "    crf = RandomForestClassifier(max_depth=i)\n",
    "    crf.fit(X_train, y_train)\n",
    "    accuracy_test.append(accuracy_score(y_val, crf.predict(X_val)))\n",
    "    accuracy_train.append(accuracy_score(y_train, crf.predict(X_train)))\n",
    "\n",
    "max_accuracy = np.max(accuracy_test)*100\n",
    "max_depth = np.argmax(accuracy_test)\n",
    "\n",
    "print('Validation set accuracy is', round(max_accuracy,3) ,'% after the maximum depth of the tree was defined is', max_depth)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(depths,accuracy_train,'bo-',depths,accuracy_test,'r*:')\n",
    "plt.grid()\n",
    "plt.legend(['Training set','Validation set'])\n",
    "plt.title('Accuracy vs Depth of the tree')\n",
    "plt.xlabel('Depths')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e720b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "# parameters = {\n",
    "#         'n_estimators': (100,300,500,700,900,1000),\n",
    "#         'min_samples_split': (1,3,5,7,9,),\n",
    "#         'min_samples_leaf':(1,3,5,7,9),\n",
    "#         'max_features':(0.5,0.8,'auto'),\n",
    "#         'max_depth':('None',25,30,35,40)\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(rf_model, parameters, cv=2)\n",
    "\n",
    "# grid.fit(X_train,y_train)\n",
    "\n",
    "# print(\"Best parameters:\", grid.best_params_)\n",
    "# print(\"Best score of training data:\", round(grid.best_score_*100,2), \"%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece3dafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "                                  max_depth=40,\n",
    "                                  max_features='auto',\n",
    "                                  n_estimators=100,\n",
    "                                  min_samples_leaf=1,\n",
    "                                  min_samples_split=1,\n",
    "                                 )\n",
    "\n",
    "rf_model.fit(X_train,y_train)\n",
    "\n",
    "y_val_pred = rf_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation set accuracy after hyperparameter tuning: \", round(accuracy*100,2), \"%\\n\")\n",
    "\n",
    "y_predicted_rf = rf_model.predict(X_test)\n",
    "y_prob_rf = rf_model.predict_proba(X_test)[:, 1] \n",
    "accuracy = rf_model.score(X_test,y_test)*100\n",
    "print(\"Random Forest Model Test Set Accuracy:\", round(accuracy,2), \"%\\n\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_predicted_rf)\n",
    "print(\"Random Forest Model Confusion Matrix: \\n\")\n",
    "conf_matrix_plot(conf_matrix)\n",
    "\n",
    "class_report = pd.DataFrame(classification_report(y_test, y_predicted_rf, output_dict=True)).transpose()\n",
    "print(\"Random Forest Model Classification Report: \\n\")\n",
    "class_report_plot(class_report)\n",
    "    \n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "\n",
    "final_memory = process.memory_info().rss\n",
    "memory_usage = final_memory - initial_memory\n",
    "\n",
    "print(\"Memory usage:\", memory_usage, 'bytes\\n')\n",
    "\n",
    "print(\"Runtime:\", round(run_time,2), 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4486a3",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca73e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "initial_memory = process.memory_info().rss\n",
    "\n",
    "# Initialize the value of C, kernel & gamma\n",
    "svm_model = SVC(C=1,kernel='rbf',gamma=0.001)\n",
    "\n",
    "feature_selection(svm_model, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbdff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = X[['Pregnancies', 'PlasmaGlucose', 'SerumInsulin', 'BMI', 'DiabetesPedigree', 'Age']]\n",
    "           \n",
    "# Split 25% data for test set\n",
    "X_rem, X_test, y_rem, y_test = train_test_split(X_data, y, test_size=0.25, random_state=6)\n",
    "\n",
    "# Split 10% data for validation set from training set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_rem, y_rem, train_size=0.9, random_state=6)\n",
    "\n",
    "svm_model.fit(X_train,y_train)\n",
    "           \n",
    "# Using validation set to observe the accuracy during model training\n",
    "y_val_pred = svm_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation set accuracy before feature selection: \", round(accuracy*100,2), \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bebe73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parameters = {'C':[1,10,100,1000],\n",
    "#                   'kernel':['linear','rbf'],\n",
    "#                   'gamma':[0.001,0.0001]}\n",
    "\n",
    "# grid = GridSearchCV(svm_model, parameters, cv=2)\n",
    "\n",
    "# grid.fit(X_train,y_train)\n",
    "\n",
    "# print(\"Best parameters:\", grid.best_params_)\n",
    "# print(\"Best score of training data:\", round(grid.best_score_*100,2), \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73a01ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svm_model = SVC(C=1000,\n",
    "               kernel='rbf',\n",
    "               gamma=0.0001,\n",
    "               probability=True)\n",
    "\n",
    "svm_model.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_predicted_svm = svm_model.predict(X_test)\n",
    "y_prob_svm = svm_model.predict_proba(X_test)[:, 1]  \n",
    "accuracy = svm_model.score(X_val,y_val)*100\n",
    "print(\"Support Vector Machine Model Validation Set Accuracy:\", round(accuracy,2), \"%\\n\")\n",
    "\n",
    "#  the accuracy of the final model on the test data\n",
    "accuracy = svm_model.score(X_test,y_test)*100\n",
    "print(\"Support Vector Machine Model Test Set Accuracy:\", round(accuracy,2), \"%\\n\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_predicted_svm)\n",
    "print(\"Support Vector Machine Model Confusion Matrix: \\n\")\n",
    "conf_matrix_plot(conf_matrix)\n",
    "\n",
    "class_report = pd.DataFrame(classification_report(y_test, y_predicted_svm, output_dict=True)).transpose()\n",
    "print(\"Support Vector Machine Model Classification Report: \\n\")\n",
    "class_report_plot(class_report)\n",
    "    \n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "\n",
    "final_memory = process.memory_info().rss\n",
    "memory_usage = final_memory - initial_memory\n",
    "\n",
    "print(\"Memory usage:\", memory_usage, 'bytes\\n')\n",
    "\n",
    "print(\"Runtime:\", round(run_time,2), 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb05f277",
   "metadata": {},
   "source": [
    "### XGBoost Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd60df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "initial_memory = process.memory_info().rss\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "feature_selection(xgb_model,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ace1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 25% data for test set\n",
    "X_rem, X_test, y_rem, y_test = train_test_split(X, y, test_size=0.25, random_state=6)\n",
    "\n",
    "# Split 10% data for validation set from training set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_rem, y_rem, train_size=0.9, random_state=6)\n",
    "\n",
    "xgb_model.fit(X_train,y_train)\n",
    "           \n",
    "# Using validation set to observe the accuracy during model training\n",
    "y_val_pred = xgb_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation set accuracy after feature selection: \", round(accuracy*100,2), \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5fe19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "# parameters = {\n",
    "#         'colsample_bytree': (0.1,0.2,0.3,0.4,0.5),\n",
    "#         'max_depth': [2,4,6,8,10],\n",
    "#         'min_child_weight': [1,3,5,7,9],\n",
    "#         'subsample':(0.5,0.6,0.7,0.8),\n",
    "#         'gamma':(0,0.1,0.2,0.3,0.5),\n",
    "#         'learning_rate':(0.1,0.2,0.3)  \n",
    "# }\n",
    "\n",
    "# random = RandomizedSearchCV(xgb_model, parameters, n_iter=30, cv=5)\n",
    "\n",
    "# random.fit(X_train,y_train)\n",
    "\n",
    "# df = pd.concat([pd.DataFrame(random.cv_results_['params']), pd.DataFrame(random.cv_results_['mean_test_score']*100, columns=['Accuracy'])] ,axis=1)\n",
    "# display(df.sort_values('Accuracy', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcaf8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier( \n",
    "                         max_depth=4, \n",
    "                         subsample=0.7,\n",
    "                         min_child_weight=1,\n",
    "                         learning_rate=0.2,\n",
    "                         gamma=0.2,\n",
    "                         colsample_bytree=0.2\n",
    "                         )random\n",
    "\n",
    "xgb_model.fit(X_train,y_train)\n",
    "\n",
    "y_val_pred = xgb_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation set accuracy after hyperparameter tuning: \", round(accuracy*100,2), \"%\\n\")\n",
    "\n",
    "y_predicted_xgboost = xgb_model.predict(X_test)\n",
    "y_prob_xgboost = xgb_model.predict_proba(X_test)[:, 1]  \n",
    "accuracy = xgb_model.score(X_test,y_test)*100\n",
    "print(\"XGBoost Model Test set accuracy: \", round(accuracy,2), \"%\\n\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_predicted_xgboost)\n",
    "print(\"XGBoost Model Confusion Matrix: \\n\")\n",
    "conf_matrix_plot(conf_matrix)\n",
    "\n",
    "class_report = pd.DataFrame(classification_report(y_test, y_predicted_xgboost, output_dict=True)).transpose()\n",
    "print(\"XGBoost Model Classification Report: \\n\")\n",
    "class_report_plot(class_report)\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "\n",
    "final_memory = process.memory_info().rss\n",
    "memory_usage = final_memory - initial_memory\n",
    "\n",
    "print(\"Memory usage:\", memory_usage, 'bytes\\n')\n",
    "\n",
    "print(\"Runtime:\", round(run_time,2), 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393c9dc3",
   "metadata": {},
   "source": [
    "### LGBM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "initial_memory = process.memory_info().rss\n",
    "\n",
    "lgbm_model = LGBMClassifier()\n",
    "\n",
    "feature_selection(lgbm_model,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301da5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 25% data for test set\n",
    "X_rem, X_test, y_rem, y_test = train_test_split(X, y, test_size=0.25, random_state=6)\n",
    "\n",
    "# Split 10% data for validation set from training set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_rem, y_rem, train_size=0.9, random_state=6)\n",
    "\n",
    "lgbm_model.fit(X_train,y_train)\n",
    "           \n",
    "# Using validation set to observe the accuracy during model training\n",
    "y_val_pred = lgbm_model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation set accuracy after feature selection: \", round(accuracy*100,2), \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96932397",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# np.random.seed(0)\n",
    "# parameters = {\n",
    "#         'colsample_bytree': (0.1,0.5,0.8),\n",
    "#         'max_depth': [5,10,15],\n",
    "#         'num_leaves': [20,30,40,50,60,70,80],\n",
    "#         'subsample':(0.5,0.8),\n",
    "#         'n_estimators':(50,100),\n",
    "# }\n",
    "\n",
    "# random = RandomizedSearchCV(lgbm_model, parameters, n_iter=30, cv=5)\n",
    "\n",
    "# random.fit(X_train,y_train)\n",
    "\n",
    "# df = pd.concat([pd.DataFrame(random.cv_results_['params']), pd.DataFrame(random.cv_results_['mean_test_score']*100, columns=['Accuracy'])] ,axis=1)\n",
    "# display(df.sort_values('Accuracy', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbbd2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lgbm_model = LGBMClassifier( max_depth=15,\n",
    "                             num_leaves= 30,\n",
    "                             n_estimators=100,\n",
    "                             subsample=0.8,\n",
    "                             colsample_bytree=0.1\n",
    "                           )\n",
    "\n",
    "lgbm_model.fit(X_train,y_train)\n",
    "\n",
    "y_val_pred = lgbm_model.predict(X_val)\n",
    "y_prob_lgbm = lgbm_model.predict_proba(X_test)[:, 1]  \n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"\\nValidation set accuracy after hyperparameter tuning: \", round(accuracy*100,2), \"%\\n\")\n",
    "\n",
    "y_predicted_lgbm = lgbm_model.predict(X_test)\n",
    "xgb_model\n",
    "accuracy = lgbm_model.score(X_test,y_test)*100\n",
    "print(\"LGBM Classifier Model Test set accuracy:\", round(accuracy,2), \"%\\n\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_predicted_lgbm)\n",
    "print(\"LGBM Classifier Model Confusion Matrix: \\n\")\n",
    "conf_matrix_plot(conf_matrix)\n",
    "\n",
    "class_report = pd.DataFrame(classification_report(y_test, y_predicted_lgbm, output_dict=True)).transpose()\n",
    "print(\"LGBM Classifier Model Classification Report: \\n\")\n",
    "class_report_plot(class_report)\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "\n",
    "final_memory = process.memory_info().rss\n",
    "memory_usage = final_memory - initial_memory\n",
    "\n",
    "print(\"Memory usage:\", memory_usage, 'bytes\\n')\n",
    "\n",
    "print(\"Runtime:\", round(run_time,2), 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b35d27",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fpr1, tpr1, thresh1 = roc_curve(y_test, y_prob_dt, pos_label=1)\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_test, y_prob_knn, pos_label=1)\n",
    "fpr3, tpr3, thresh3 = roc_curve(y_test, y_prob_lr, pos_label=1)\n",
    "fpr4, tpr4, thresh4 = roc_curve(y_test, y_prob_svm, pos_label=1)\n",
    "fpr5, tpr5, thresh5 = roc_curve(y_test, y_prob_rf, pos_label=1)\n",
    "fpr6, tpr6, thresh6 = roc_curve(y_test, y_prob_xgboost, pos_label=1)\n",
    "fpr7, tpr7, thresh7 = roc_curve(y_test, y_prob_lgbm, pos_label=1)\n",
    "\n",
    "auc1 = round(roc_auc_score(y_test, y_prob_dt), 4)\n",
    "auc2 = round(roc_auc_score(y_test, y_prob_knn), 4)\n",
    "auc3 = round(roc_auc_score(y_test, y_prob_lr), 4)\n",
    "auc4 = round(roc_auc_score(y_test, y_prob_svm), 4)\n",
    "auc5 = round(roc_auc_score(y_test, y_prob_rf), 4)\n",
    "auc6 = round(roc_auc_score(y_test, y_prob_xgboost), 4)\n",
    "auc7 = round(roc_auc_score(y_test, y_prob_lgbm), 4)\n",
    "\n",
    "print(auc5)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "plt.plot(fpr1,tpr1,color='red', linestyle='-', marker='o', linewidth=3, label= \"Decision Tree AUC=\"+str(auc1))\n",
    "plt.plot(fpr2,tpr2,color='orange', linestyle='-', marker='o', linewidth=3, label= \"K Nearest Neighbor AUC=\"+str(auc2))\n",
    "plt.plot(fpr3,tpr3,color='yellow', linestyle='-', marker='o', linewidth=3, label= \"Logistics Regression AUC=\"+str(auc3))\n",
    "plt.plot(fpr4,tpr4,color='green', linestyle='-', marker='o', linewidth=3, label= \"Support Vector Machine AUC=\"+str(auc4))\n",
    "plt.plot(fpr5,tpr5,color='blue', linestyle='-', marker='o', linewidth=3, label= \"Random Forest AUC=\"+str(auc5))\n",
    "plt.plot(fpr6,tpr6,color='purple', linestyle='-', marker='o', linewidth=3, label= \"XGBoost AUC=\"+str(auc6))\n",
    "plt.plot(fpr7,tpr7,color='pink', linestyle='-', marker='o', linewidth=3, label= \"Lignt-GBM AUC=\"+str(auc7))\n",
    "\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.title('AUC ROC Plot',size=20)\n",
    "plt.xlabel('False Positive',size=15)\n",
    "plt.ylabel('True Positive',size=15)\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc6816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "dt_precision, dt_recall, _ = precision_recall_curve(y_test, y_prob_dt)\n",
    "knn_precision, knn_recall, _ = precision_recall_curve(y_test, y_prob_knn)\n",
    "lr_precision, lr_recall, _ = precision_recall_curve(y_test, y_prob_lr)\n",
    "svm_precision, svm_recall, _ = precision_recall_curve(y_test, y_prob_svm)\n",
    "rf_precision, rf_recall, _ = precision_recall_curve(y_test, y_prob_rf)\n",
    "xgboost_precision, xgboost_recall, _ = precision_recall_curve(y_test, y_prob_xgboost)\n",
    "lgbm_precision, lgbm_recall, _ = precision_recall_curve(y_test, y_prob_lgbm)\n",
    "\n",
    "dt_auc = auc(dt_recall, dt_precision).round(3)\n",
    "knn_auc = auc(knn_recall, knn_precision).round(3)\n",
    "lr_auc = auc(lr_recall, lr_precision).round(3)\n",
    "svm_auc = auc(svm_recall, svm_precision).round(3)\n",
    "rf_auc = auc(rf_recall, rf_precision).round(3)\n",
    "xgboost_auc = auc(xgboost_recall, xgboost_precision).round(3)\n",
    "lgbm_auc = auc(lgbm_recall, lgbm_precision).round(3)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(dt_recall,dt_precision,color='red', linestyle='--', marker='o', linewidth=3, label= \"Decision Tree AUC=\"+str(dt_auc))\n",
    "plt.plot(knn_recall,knn_precision,color='orange', linestyle='--', marker='o', linewidth=3, label= \"K Nearest Neighbor AUC=\"+str(knn_auc))\n",
    "plt.plot(lr_recall,lr_precision,color='yellow', linestyle='--', marker='o', linewidth=1, label= \"Logistics Regression AUC=\"+str(lr_auc))\n",
    "plt.plot(svm_recall,svm_precision,color='green', linestyle='--', marker='o', linewidth=3, label= \"Support Vector Machine AUC=\"+str(svm_auc))\n",
    "plt.plot(rf_recall,rf_precision,color='blue', linestyle='--', marker='o', linewidth=3, label= \"Random Forest AUC=\"+str(rf_auc))\n",
    "plt.plot(xgboost_recall,xgboost_precision,color='purple', linestyle='--', marker='o', linewidth=3, label= \"XGBoost AUC=\"+str(xgboost_auc))\n",
    "plt.plot(lgbm_recall,lgbm_precision,color='pink', linestyle='--', marker='o', linewidth=3, label= \"Lignt-GBM AUC=\"+str(lgbm_auc))\n",
    "\n",
    "\n",
    "plt.grid()\n",
    "plt.title('PR Curve',size=20)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Recall',size=15)\n",
    "plt.ylabel('Precision',size=15)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cf48c9",
   "metadata": {},
   "source": [
    "## Deploy the highest accuracy model ( LGBM Classfier Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308804c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(knn_model, open('model.pkl', 'wb'))\n",
    "\n",
    "model = pickle.load(open('model.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193de745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
